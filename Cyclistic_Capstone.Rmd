---
title: "Cyclistic Capstone"
author: "Jessica"
date: "2/25/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Note
This is a case study based on a fictional company for the Google Data Analytics certificate capstone called Cyclistic.  This information is from Divvy Bikes which based in Chicago. Also while doing working this information, I used the Divvy site for locating stations and Google Maps for using coordinates. 

## Stakeholders
* Lily Moreno, Director of Marketing
* Cyclistic Marketing Analytics team
* Cyclistic Executive team


## About Cyclistic
Cyclistic launched a successful bike-share offering in 2016.  Since then, the program has grown to a fleet of 5824 bicycles that are geotracked and locked into a network of 692 stations across Chicago.  The bikes can be unlocked from one station and returned to any other station in the system anytime.

Until now, Cyclistic's marketing strategy relied on building general awareness and appealing to broad consumer segments.  One approach that helped make these things possible was the flexibility of
its pricing plans: single-ride passes, full-day passes, and annual memberships.  Customers who purchase single-ride or full-day passes are referred to as casual riders.  Customer who purchase annual memberships are Cyclistic members.
There are three bike types: electric bikes, docked bikes, and classic bikes.  

Electric bikes are the newest bikes.  They do have a battery that helps with pedaling and give you more control.  Ebikes can be docked at official Cyclistic ebike docks or lock them at private locations like other regualar bike docks.

Docked bikes are the second generation bikes.  They work just like ebikes.  They can be docked or locked in private locations.

The classic bike is the first generation and they are the not electric.  Classic bikes can only be docked at bike racks for classic bikes.

Cyclistic's finance analysts have concluded that annual members are much more profitable than casual riders.  Although the the pricing flexibility helps Cyclistic attract more customers, Moreno believes that maximizing the number of annual members will be key to future growth.  rather than creating a marketing campaign that targets all-new customers, Moreno there is a very good chance to convert casual riders into members.  She notes that casual riders are already aware of the Cyclistic program and have chosen Cyclistic for their mobility needs.

## Business Task
The purpose of this project is to understand how Cyclistic's annual members and casual riders use the service.

This information may be used to  determine why casual riders buy Cyclistic annual memberships and to drive them to purchase annual memberships.  The project will identify how long are bikes used for,  the top 10 start and end stations, and possible locations and destinations.  Other trends would include if the bikes were used in one way trips or a round trip and which bike does each member typically use.

## Scope of Work
A scope of work was created to help plan.  That can be found [here](https://docs.google.com/document/d/1gXx_AMnOsY-Ozoi3eEhaiCw5LrE6asrLq46AfeJUO1A/edit?usp=sharing&resourcekey=0-PHR4daSvHnnIVllFhFibNg)


## Description of Data Sources used
All the data was provided by Cyclistic.  This is public data that is provided by Cyclistic under this Data License Agreement [linked here] (https://ride.divvybikes.com/data-license-agreement). As you can see this information is not comprehensive or complete, but for this case study the data will help with the business statement. This case study will only use the data between Jan 2021 to Jan 2022.  The data will be used only for this case study and then deleted.  The original data will not be changed or altered in any way.  The data taken will be a copy.

## Detailed Summary of Processing and Cleaning

#### Install needed packages

```{r library}
library(tidyverse) #for datasets
library("lubridate") #need this for dates
library(dplyr) #for data manipulation
library(ggplot2) #for elegant data viz presentation
```

#### Import datasets

```{r data}
`202101.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/01_2021divvy-tripdata/202101-divvy-tripdata.csv")
`202102.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/02_2021divvy-tripdata/202102-divvy-tripdata.csv")
`202103.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/03_2021divvy-tripdata/202103-divvy-tripdata.csv")
`202104.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/04_2021divvy-tripdata/202104-divvy-tripdata.csv")
`202105.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/05_2021divvy-tripdata/202105-divvy-tripdata.csv")
`202106.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/06_2021divvy-tripdata/202106-divvy-tripdata.csv")
`202107.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/07_2021divvy-tripdata/202107-divvy-tripdata.csv")
`202108.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/08_2021divvy-tripdata/202108-divvy-tripdata.csv")
`202109.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/09_2021divvy-tripdata/202109-divvy-tripdata.csv")
`202110.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/10_2021divvy-tripdata/202110-divvy-tripdata.csv")
`202111.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/11_2021divvy-tripdata/202111-divvy-tripdata.csv")
`202112.divvy.tripdata` <- read.csv("~/Cyclistic_Case_Study/Cyclistic_Capstone/Used/12_2021divvy-tripdata/202112-divvy-tripdata.csv")
```

#### A look

```{r datasets}
str(`202101.divvy.tripdata`)
str(`202102.divvy.tripdata`)
str(`202103.divvy.tripdata`)
str(`202104.divvy.tripdata`)
str(`202105.divvy.tripdata`)
str(`202106.divvy.tripdata`)
str(`202107.divvy.tripdata`)
str(`202108.divvy.tripdata`)
str(`202109.divvy.tripdata`)
str(`202110.divvy.tripdata`)
str(`202111.divvy.tripdata`)
str(`202112.divvy.tripdata`)
```

####Combine into one 

```{r combine all tables}
bikes_2021 <- bind_rows(
  `202101.divvy.tripdata`,
  `202102.divvy.tripdata`,
  `202103.divvy.tripdata`,
  `202104.divvy.tripdata`,
  `202105.divvy.tripdata`,
  `202106.divvy.tripdata`,
  `202107.divvy.tripdata`,
  `202108.divvy.tripdata`,
  `202109.divvy.tripdata`,
  `202110.divvy.tripdata`,
  `202111.divvy.tripdata`,
  `202112.divvy.tripdata`,
)
summary(bikes_2021)
```

I started by look at the first month on excel to familarize myself with the data.  I know that the NA have no recorded data.
Going off the summary from the previous we have NA's in the End latitude and longitude columns to get rid of.  These look like bikes that were stolen or lost. We will also check for duplicates and remove those if any.

```{r deleting entries and duplicates}
## Deletes rows with NA in the end_lat column 
bikes_2021_v2 <- bikes_2021[!is.na(bikes_2021$end_lat),]  
summary(bikes_2021_v2)

# pulls the duplicates by ride_id
bikes_2021$ride_id[duplicated(bikes_2021$ride_id)]

```

There are no duplicates. The entires with NA's in end_lat and end_long are gone.  We have to find the bikes rides that correspond to repairs and quality checks.  They are supposed to be under HQ QR.

``` {r Looking for HQ QR}
bikes_2021_v2 %>% 
  count(start_station_name)  # pulls up all starting stations
options(max.print = 10000000)  # previous was very long so increasing how much it will print
bikes_2021_v2 %>% 
  count(start_station_name)
```

So we have nothing called HQ QR.  We do have Base - 2132 W Hubbard Warehouse, Throop/Hastings Mobile Station, DIVVY CASSETTE REPAIR MOBILE STATION, Throop/Hastings Mobile Station, and Base - 2132 W Hubbard Warehouse.  Those might be testing/repair sites.  We have to check for this.  We also have something called the Lyft Driver Center Private Rack. Also note that we have 770902 stations with no names.  
Some have (NU) after a location, for example like "Sheridan Rd & Noyes St (NU)", but that might have to do with Northwestern university. A Google maps look confirms it.  Then we have those that have (temp) after it like "Pulaski Rd & Eddy St (Temp)".  Temp must stand for temporary so those stay, too. There is a duplicate of "Halstead St & 18th St", but one has the (temp) after it.  We have to check that one.  

```{R end station names}
# a list of the ending stations
bikes_2021_v2 %>% 
  count(end_station_name)
```

So again we have 820069 stations rides with blanks.  More than the start station list.  The same locations noted earlier are here too.  

```{r Station ids}

bikes_2021_v2 %>% 
  count(start_station_id) #for the start station ids
bikes_2021_v2 %>% 
  count(end_station_id) # for the end station ids
```

These are easy to peruse since most are serials of numbers and letters.  We have Throop/Hastings Mobile Station, DIVVY CASSETTE REPAIR MOBILE STATION, Hubbard Bike-checking (LBS-WH-TEST, DIVVY 001. Start station ids have 770899 blanks and end station ids have 770878 blanks.   Let's start checking these out.

```{r checking locations}
#  pulls Cassette repair, Lyft rack, Throop mobile both starting and ending stations
bikes_2021_v2 %>% 
  filter(start_station_name == "DIVVY CASSETTE REPAIR MOBILE STATION" | start_station_name == "Lyft Driver Center Private Rack" | start_station_name == "Throop/Hastings Mobile Station" | end_station_name == "DIVVY CASSETTE REPAIR MOBILE STATION" | end_station_name == "Lyft Driver Center Private Rack" | end_station_name == "Throop/Hastings Mobile Station")
```

These are the start/end station names with the smallest occurrences.  Together they are 14.  First off, found some of the blanks.  These have a coordinate that is rounded. It seems that a too general latitude or longitude returns no location. Throop/Hastings might be another repair mobile.  Notice how one ends where the next starts in coordinates and time started/ended.  

Lyft Driver Center Private Rack coordinates drop us near the Kennedy Expressway.  They were only taken there for 8 minutes and dropped off at Kingsbury St & Kinzie St.  This is not the closest Divvy station, but according to Google Maps it would take about that long by car and bike.  So that checks out.  I did find a Chicago Lyft Driver Center a few blocks from this location.  This is where Lyft drivers go for repairs.  (Note:  the dataset comes from the Chicago Divvy bike share which is managed by Lyft)  They might come from here actually.  Especially since the coordinates are rounded like some of the blanks.  This data shows two bikes being picked up from untracked locations to the Lyft Driver Center then returned to the Kingsbury and Kinzie location.  

Divvy Cassette Repair Mobile station seems to pick up bikes in areas fix them and then returns them.  The coordinates show the two coordinates for rides ending at Lake Shore Dr are very similar.  Field Museum is just a mile away so not too far. Maybe the rack was full of bikes so they went to the next closest one, just down the way.   

In conclusion, we can get rid of these without effecting the analysis too much.  Also note that the blanks one here all come from the electric bikes.  

``` {r checking locations 2}
# pulls rides at Halseted St and 18th 'duplicates'
bikes_2021_v2 %>% 
  filter(start_station_name == "Halsted St & 18th St (Temp)") %>% 
  arrange(started_at)  #Ran these separately in pairs
bikes_2021_v2 %>% 
  filter(start_station_name == "Halsted St & 18th St") %>% 
  arrange(started_at)
bikes_2021_v2 %>% 
  filter(end_station_name == "Halsted St & 18th St (Temp)") %>% 
  arrange(started_at)
bikes_2021_v2 %>% 
  filter(end_station_name == "Halsted St & 18th St") %>% 
  arrange(started_at)
```

So the temporary Halsted St location is located on 17th St, just around the corner.  It started in July and went to the end of the year, but at this time is no longer active.  They added another location for some reason, but they are valid rides.  Also notice that the blanks here are also electric bikes.


```{r checking locations 3}
# a look at base -2132 hubbard
bikes_2021_v2 %>% 
  filter(start_station_name == "Base - 2132 W Hubbard Warehouse") %>% 
  arrange(started_at)
bikes_2021_v2 %>% 
  filter(end_station_name == "Base - 2132 W Hubbard Warehouse") %>% 
  arrange(started_at)
```

Base - 2132 W Hubbard Warehouse is associated with the station id Hubbard Bike-Checking.  So all rides going to and heading out of Hubbard will be taken out.

```{r checking station ids}
# a look at the possible repair stations from their ids
bikes_2021_v2 %>% 
  filter(start_station_id == "Hubbard Bike-checking (LBS-WH-TEST)" | end_station_id == "Hubbard Bike-checking (LBS-WH-TEST)")
bikes_2021_v2 %>% 
  filter(start_station_id == "DIVVY 001" | end_station_id == "DIVVY 001")
```

These Divvy 001 rides don't lead back to a station.  There is one very close by on Chicago Ave & Kildare Ave.  Also the duration of these rides are appear to be very small.  Let's create a duration row to help with this. First, the start time and end time columns are in character so let's create new rows in numeric to do some subtracting to get our ride duration column.

```{r pull times}
#set the start and end times as date time to do some equations later
bikes_2021_v2$time_started <- as_datetime(bikes_2021_v2$started_at)
bikes_2021_v2$time_ended <- as_datetime(bikes_2021_v2$ended_at)
str(bikes_2021_v2)
```

Now we subtract the time ended from the time started to get the result in seconds.

```{r duration and correct format}
bikes_2021_v2$duration <- difftime(bikes_2021_v2$time_ended, bikes_2021_v2$time_started,) # create the duration column
str(bikes_2021_v2)
is.factor(bikes_2021_v2$duration)  # check the factor
bikes_2021_v2$duration <- as.numeric(as.character(bikes_2021_v2$duration))
is.numeric(bikes_2021_v2$duration) # check is numeric
```

Now we run the Divvy filter again.

```{r checking station ids}
# pulling stations with ids Divvy 001 and stations with west chi watson
bikes_2021_v2 %>% 
  filter(start_station_id == "DIVVY 001" | end_station_id == "DIVVY 001"  | start_station_name == "WEST CHI-WATSON" | end_station_name == "WEST CHI-WATSON") %>% 
  arrange(duration)
```

These are not rounded coordinates like the blanks.  All of them do not go to an official bike station and are electric bikes.  Most of them are used for a few seconds.  I haven't made a decision yet on what will be considered a valid ride duration.  I'll have to look at how long are rides that go from one station to the same station.  However because so many go to the same place and are only used for a few seconds, I'm inclined to think that station id DIVVY 001 and station WEST CHI-WATSON are just another repair station or a testing site.  

``` {r double checking}
# 
bikes_2021_v2 %>% 
  filter(start_station_name == "DIVVY CASSETTE REPAIR MOBILE STATION" | start_station_name == "Lyft Driver Center Private Rack" | start_station_name == "Throop/Hastings Mobile Station" | start_station_name == "WEST CHI-WATSON" | start_station_name == "Base - 2132 W Hubbard Warehouse") %>% 
  count(start_station_name, start_station_id) %>% 
  arrange(start_station_id)

bikes_2021_v2 %>% 
  filter(end_station_name == "DIVVY CASSETTE REPAIR MOBILE STATION" | end_station_name == "Lyft Driver Center Private Rack" | end_station_name == "Throop/Hastings Mobile Station" | end_station_name == "WEST CHI-WATSON" | end_station_name == "Base - 2132 W Hubbard Warehouse") %>% 
  count(end_station_id, end_station_name) %>% 
  arrange(end_station_id)
```

So the station names are connected to one station.  Now let's double check it works in reverse.

``` {r double checking 2}
bikes_2021_v2 %>% 
  filter(start_station_id == "20999" | start_station_id == "DIVVY 001" | start_station_id == "DIVVY CASSETTE REPAIR MOBILE STATION" | start_station_id == "Hubbard Bike-checking (LBS-WH-TEST)" | start_station_id == "Throop/Hastings Mobile Station") %>% 
  count(start_station_name, start_station_id) %>% 
  arrange(start_station_id)

bikes_2021_v2 %>% 
  filter(end_station_id == "20999" | end_station_id == "DIVVY 001" | end_station_id == "DIVVY CASSETTE REPAIR MOBILE STATION" | end_station_id == "Hubbard Bike-checking (LBS-WH-TEST)" | end_station_id == "Throop/Hastings Mobile Station") %>% 
  count(end_station_name, end_station_id) %>% 
  arrange(end_station_id)
  
```

All right they match up.  Now to double check the others. I want to make sure that stations match up with station IDs.  Then we have to check out those blank station names.

```{r double checking 3}
bikes_2021_v2 %>% 
  group_by(start_station_id) %>% 
  summarise(no.unique.names = n_distinct(start_station_name), unique_names = str_c(unique(start_station_name), collapse = ",  ")) %>% 
  filter(no.unique.names > 1) 

bikes_2021_v2 %>% 
  group_by(end_station_id) %>% 
  summarise(no.unique.names = n_distinct(end_station_name), unique_names = str_c(unique(end_station_name), collapse = ",  ")) %>% 
  filter(no.unique.names > 1)
```
So we have a start station name by 351 and TA1305000039 refers to 2 stations: Marshfield Ave & Cortland St, Elston Ave & Cortland St and TA1306000029	refers to 3 stations:	Lake Shore Dr & Ohio St, DuSable Lake Shore Dr & Ohio St, McClurg Ct & Ohio St.  A few of them have a DuSable in front of them.  DuSable is a common name in Chicago derived from Jean Baptiste Point du Sable

Most of the duplicates refer to the extra station nearby, but we'll double check these.  

```{r double checking 4}
bikes_2021_v2 %>% 
  filter(start_station_id == "351") %>% 
  arrange(start_at)

bikes_2021_v2 %>% 
  filter(start_station_id == "TA1306000029") %>% 
  arrange(started_at)

bikes_2021_v2 %>% 
  filter(start_station_id == "TA1305000039") %>% 
  arrange(started_at)

bikes_2021_v2 %>% 
  filter(end_station_id == "351" | end_station_id == "TA1305000039" | end_station_id == "TA1306000029") %>% 
  arrange(end_station_id)

```

Anything with start_station_name '351' needs to be renamed 'Mulligan Ave & Wellington Ave'.  It appears to be an error there.  Station ID TA1305000039 refers to Marshfield Ave & Cortland St until late May when Elston Ave & Cortland St takes over for the rest of the year. Then station id TA1305000039 starts at Lake Shore Dr & Ohio St then doesn't move but changes names to DuSable Lake Shore Dr & Ohio St.  From looking at a map, Lake Shore Dr is the name of the street, Dusable Lake Shore Dr is the name of the 'highway' next to it. Also in October, Lake Shore Dr was renamed DuSable Lake shore Dr. Then in December was moved down the street to McClurg Ct.

In summary, the duplicates are because the a street was renamed, vaccination sites, and stations being moved to different places. 

We do have to change any station with the name 351 to Mulligan Ave & Wellington Ave.
We need to delete the repair stations names and ids: Throop/Hastings Mobile Station, DIVVY CASSETTE REPAIR MOBILE STATION, Hubbard Bike-checking (LBS-WH-TEST), DIVVY 001, Base - 2132 W Hubbard Warehouse, Lyft Driver Center Private Rack, and WEST CHI-WATSON



Now let's delete those rows and then check to see if it worked.
```{r removing rows}
# removing rows
bikes_2021_v3 <- bikes_2021_v2[!(bikes_2021_v2$start_station_name == "DIVVY CASSETTE REPAIR MOBILE STATION" | bikes_2021_v2$start_station_name == "Lyft Driver Center Private Rack" | bikes_2021_v2$start_station_name == "Throop/Hastings Mobile Station" | bikes_2021_v2$start_station_name == "WEST CHI-WATSON" | bikes_2021_v2$start_station_name == "Base - 2132 W Hubbard Warehouse" | bikes_2021_v2$start_station_id == "Hubbard Bike-checking (LBS-WH-TEST)" | bikes_2021_v2$start_station_name == "DIVVY 001" ),]

# Checking rows are gone
bikes_2021_v3 %>% 
  filter(start_station_name == "DIVVY CASSETTE REPAIR MOBILE STATION" | start_station_name == "Lyft Driver Center Private Rack" | start_station_name == "Throop/Hastings Mobile Station"| start_station_name == "WEST CHI-WATSON" | start_station_name == "Base - 2132 W Hubbard Warehouse" | start_station_id == "Hubbard Bike-checking (LBS-WH-TEST)" | start_station_name == "DIVVY 001" )

# removing rows
bikes_2021_v4 <- bikes_2021_v3[!(bikes_2021_v3$end_station_name == "DIVVY CASSETTE REPAIR MOBILE STATION" | bikes_2021_v3$end_station_name == "Lyft Driver Center Private Rack" | bikes_2021_v3$end_station_name == "Throop/Hastings Mobile Station" | bikes_2021_v3$end_station_name == "WEST CHI-WATSON" | bikes_2021_v3$end_station_name == "Base - 2132 W Hubbard Warehouse" | bikes_2021_v3$end_station_id == "Hubbard Bike-checking (LBS-WH-TEST)" | bikes_2021_v3$end_station_name == "DIVVY 001" ),]

# Checking rows are gone
bikes_2021_v4 %>% 
  filter(end_station_name == "DIVVY CASSETTE REPAIR MOBILE STATION" | end_station_name == "Lyft Driver Center Private Rack" | end_station_name == "Throop/Hastings Mobile Station"| end_station_name == "WEST CHI-WATSON" | end_station_name == "Base - 2132 W Hubbard Warehouse" | end_station_id == "Hubbard Bike-checking (LBS-WH-TEST)" | end_station_name == "DIVVY 001" )
```

Rename station names with '351' to the correct name.  

```{r renaming stations}
# pulls the rides with ids 351
bikes_2021_v4 %>% 
  filter(start_station_id == "351") %>% 
  arrange(start_station_name)
# changes those specific rides with 351 as a station name to the correct name
bikes_2021_v4$start_station_name[bikes_2021_v4$ride_id == "5E181D51F7C391F4"] = "Mulligan Ave & Wellington Ave"
bikes_2021_v4$start_station_name[bikes_2021_v4$ride_id == "3036610505F382EF"] = "Mulligan Ave & Wellington Ave"
# pulls those specific rides again to check
bikes_2021_v4 %>% 
  filter(ride_id == "5E181D51F7C391F4" | ride_id == "3036610505F382EF")
```

Those rides erros have been corrected.
Now to look at those blanks
```{r blanks}
# Can we see them listed here? No
summary(bikes_2021_v4)

# let's look at all the starting station names
bikes_2021_v4 %>% 
  count(start_station_name)

# a look at all the ending station names
bikes_2021_v4 %>% 
  count(end_station_name)
```

We have a negative time as a duration.  We have 690688 blank starting station and 734257 blank ending stations.  I'm guessing we have a some rides that have both blank ending and starting stations.

```{r blank station}
# pulls all the blank starting names
bikes_2021_v4 %>% 
  filter(start_station_name == "")

```

So just quickly glancing over it looks like the electric bike has some issues with recording the starting stations. It might be an error I have to overlook since removing over 600,000 entries for electric bikes would impact the data for electric bikes

``` {r checking blank ending stations}
# pulls the blank ending stations
bikes_2021_v4 %>% 
  filter(end_station_name == "") %>% 
  select(rideable_type, start_station_name, end_station_name, start_lng, end_lng)

```

With the blank ending ones we have the same problem.  It does seem to be the electric bikes.  Unlike the NA's we deleted that had no listed coordinates, these have recorded coordinates and times.  The name of the station is lost somehow.  I am really reluctant to delete these since 800,000 would be a big hit.

We might be able to source possible locations for some, but the coordinates from the correctly recorded rides are very exact.  These are very rounded.  They will apply to many stations. Since ebikes can be locked at private locations, that could describe these issues.  It looks like the bikes are locked and then the ride ends.  Then the user comes back and unlocks the bike and a new ride begins.  It would be interesting to try and connect those rides together but it's not included in the scope of the project.

``` {r summary}
# a look at the earliest time each bike type was used.
bikes_2021_v4 %>% 
  group_by(rideable_type) %>% 
  summarise(earliest = min(started_at))


summary(bikes_2021_v4)

```

We still have those a negative duration rides to look at.  I wonder if any have to do with day light savings.  I've seen some rides go from late at night to early in the morning.  Daylight Savings would impact those riders.

``` {r negative durations}
bikes_2021_v4 %>% 
  filter(duration <= 1) %>% 
  select(ride_id, start_station_name, end_station_name, time_started, time_ended, duration) %>% 
  arrange(time_started)

```
Daylight saving time for 2021 does happen on March 14th at 2am.  Time moves forward an hour
Then in November 7th, time is moved back an hour. This is our main focus with the negative duration values.  I also want to look at the spread of negative values.
So we have ride B1235D38EB2F8A9E that has a negative duration on Jan 6th.
March 29th we have have -1 sec ride. This one didn't move so we safely erase this.  Another one on April 7th for -7 seconds.  They are spaced about with minor time differences.  The blank entries are here, but only a portion of them.  These are bikes that just didn't move.  



##### Later
 
```{r summary and new columns}

bikes_2021$start_date <- as.Date(bikes_2021$started_at)
bikes_2021$month <- format(as.Date(bikes_2021$start_date), "%m")
bikes_2021$day <- format(as.Date(bikes_2021$start_date), "%d")
bikes_2021$year <- format(as.Date(bikes_2021$start_date), "%Y")
bikes_2021$day_of_week <- format(as.Date(bikes_2021$start_date), "%A")
str(bikes_2021$start_date)
str(bikes_2021)
``` 








```{r summary}
str(bikes_2021)
summary(bikes_2021)
```








#### Create clean 


```{r HQ check}
mean(bikes_2021$duration)
median(bikes_2021$duration)
max(bikes_2021$duration) 
min(bikes_2021$duration)

#The max is very high.  So let's check that one out.  There are two that come up and they are valid.

annual_trips[annual_trips$duration == '55944.15',]

```





##Analysis

summary(bikes_2021$duration)

summary()

aggregate(annual_trips$duration ~ annual_trips$member_casual, FUN = mean)
aggregate(annual_trips$duration ~ annual_trips$member_casual, FUN = median)
aggregate(annual_trips$duration ~ annual_trips$member_casual, FUN = max)
aggregate(annual_trips$duration ~ annual_trips$member_casual, FUN = min)

aggregate(annual_trips$duration ~ annual_trips$member_casual + annual_trips$day_of_week, FUN = mean)

annual_trips$day_of_week <- ordered(annual_trips$day_of_week, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))

aggregate(annual_trips$duration ~ annual_trips$member_casual + annual_trips$day_of_week, FUN = mean)



